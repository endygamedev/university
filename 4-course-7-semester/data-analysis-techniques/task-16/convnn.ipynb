{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\n\nimport torch.nn as nn\nfrom torchvision import transforms","metadata":{"execution":{"iopub.status.busy":"2022-11-17T14:07:23.828594Z","iopub.execute_input":"2022-11-17T14:07:23.829027Z","iopub.status.idle":"2022-11-17T14:07:23.834593Z","shell.execute_reply.started":"2022-11-17T14:07:23.828989Z","shell.execute_reply":"2022-11-17T14:07:23.833520Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\">\n\n<h3> Задание (выполнять в отдельном файле)</h3>\n<p></p>\nРеализовать сверточную нейронную сеть заданной архитектуры для решения задачи бинарной классификации: снаружи или внутри помещения сделана фотография.\n <p></p>\n</div>","metadata":{}},{"cell_type":"code","source":"base_dir = '/kaggle/input/cian-datafest-2019/train.zip'\n\nimport zipfile\nwith zipfile.ZipFile(base_dir, 'r') as z:\n    z.extractall()","metadata":{"execution":{"iopub.status.busy":"2022-11-17T14:07:23.840150Z","iopub.execute_input":"2022-11-17T14:07:23.840480Z","iopub.status.idle":"2022-11-17T14:07:35.360367Z","shell.execute_reply.started":"2022-11-17T14:07:23.840454Z","shell.execute_reply":"2022-11-17T14:07:35.359384Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    dev = 'cuda:0'\nelse:\n    dev = 'cpu'\ndevice = torch.device(dev)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T14:07:35.362342Z","iopub.execute_input":"2022-11-17T14:07:35.362693Z","iopub.status.idle":"2022-11-17T14:07:35.368011Z","shell.execute_reply.started":"2022-11-17T14:07:35.362658Z","shell.execute_reply":"2022-11-17T14:07:35.366953Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([transforms.Resize((56, 56)),\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrain_data = torchvision.datasets.ImageFolder(\"./train\", transform=transform)\n\ntrainset = torch.utils.data.Subset(train_data, list(range(0, len(train_data), 6)))","metadata":{"execution":{"iopub.status.busy":"2022-11-17T14:13:13.905550Z","iopub.execute_input":"2022-11-17T14:13:13.905907Z","iopub.status.idle":"2022-11-17T14:13:14.109068Z","shell.execute_reply.started":"2022-11-17T14:13:13.905877Z","shell.execute_reply":"2022-11-17T14:13:14.107962Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"len(trainset)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T14:13:14.113612Z","iopub.execute_input":"2022-11-17T14:13:14.114473Z","iopub.status.idle":"2022-11-17T14:13:14.121711Z","shell.execute_reply.started":"2022-11-17T14:13:14.114430Z","shell.execute_reply":"2022-11-17T14:13:14.120520Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"9221"},"metadata":{}}]},{"cell_type":"code","source":"train_set, val_set = torch.utils.data.random_split(trainset, [6000, 3221])","metadata":{"execution":{"iopub.status.busy":"2022-11-17T14:13:14.265215Z","iopub.execute_input":"2022-11-17T14:13:14.265516Z","iopub.status.idle":"2022-11-17T14:13:14.271532Z","shell.execute_reply.started":"2022-11-17T14:13:14.265492Z","shell.execute_reply":"2022-11-17T14:13:14.270378Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(dataset=train_set, \n                                           batch_size=100, \n                                           shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(dataset=val_set, \n                                          batch_size=100, \n                                          shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T14:32:15.793553Z","iopub.execute_input":"2022-11-17T14:32:15.794097Z","iopub.status.idle":"2022-11-17T14:32:15.804656Z","shell.execute_reply.started":"2022-11-17T14:32:15.794054Z","shell.execute_reply":"2022-11-17T14:32:15.803601Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"class CustomNet(nn.Module):\n    def __init__(self):\n        super(CustomNet, self).__init__()\n        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1)\n        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=1)\n        self.conv_layer3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=8, stride=1)\n        self.pooling_layer1 = nn.AvgPool2d(kernel_size=2)\n        self.pooling_layer2 = nn.AvgPool2d(kernel_size=3)\n        \n        self.linear_layer1 = nn.Linear(in_features=128, out_features=64)\n        self.linear_layer2 = nn.Linear(in_features=64, out_features=32)\n        self.linear_layer3 = nn.Linear(in_features=32, out_features=1)\n        \n        self.relu = nn.ReLU()\n        \n    def forward(self, inputs):\n        output_1 = self.relu(self.conv_layer1(inputs))\n        output_2 = self.pooling_layer1(output_1)\n        output_3 = self.relu(self.conv_layer2(output_2))\n        output_4 = self.pooling_layer2(output_3)\n        output_5 = self.relu(self.conv_layer3(output_4))\n        output_6 = torch.flatten(output_5, 1)\n        \n        output_7 = self.relu(self.linear_layer1(output_6))\n        output_8 = self.relu(self.linear_layer2(output_7))\n        output = self.linear_layer3(output_8)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2022-11-17T14:32:19.633629Z","iopub.execute_input":"2022-11-17T14:32:19.633975Z","iopub.status.idle":"2022-11-17T14:32:19.644326Z","shell.execute_reply.started":"2022-11-17T14:32:19.633944Z","shell.execute_reply":"2022-11-17T14:32:19.643246Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"class NewCustomNet(nn.Module):\n    def __init__(self):\n        super(NewCustomNet, self).__init__()\n        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3, stride=1, padding=1)\n        self.conv_layer2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n        self.conv_layer3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n        self.conv_layer4 = nn.Conv2d(in_channels=256, out_channels=4096, kernel_size=7, stride=1)\n        self.pooling_layer1 = nn.MaxPool2d(kernel_size=2)\n        self.pooling_layer2 = nn.MaxPool2d(kernel_size=2)\n        self.pooling_layer3 = nn.MaxPool2d(kernel_size=2)\n        \n        self.linear_layer1 = nn.Linear(in_features=4096, out_features=1000)\n        self.linear_layer2 = nn.Linear(in_features=1000, out_features=1)\n        \n        self.relu = nn.ReLU()\n        \n    def forward(self, inputs):\n        output_1 = self.relu(self.conv_layer1(inputs))\n        output_2 = self.pooling_layer1(output_1)\n        output_3 = self.relu(self.conv_layer2(output_2))\n        output_4 = self.pooling_layer2(output_3)\n        output_5 = self.relu(self.conv_layer3(output_4))\n        output_6 = self.pooling_layer3(output_5)\n        output_7 = self.relu(self.conv_layer4(output_6))\n        output_8 = torch.flatten(output_7, 1)\n        \n        output_9 = self.relu(self.linear_layer1(output_8))\n        output = self.linear_layer2(output_9)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2022-11-17T14:35:35.038911Z","iopub.execute_input":"2022-11-17T14:35:35.039291Z","iopub.status.idle":"2022-11-17T14:35:35.051111Z","shell.execute_reply.started":"2022-11-17T14:35:35.039257Z","shell.execute_reply":"2022-11-17T14:35:35.050010Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"model = CustomNet().to(device)\n# model = NewCustomNet().to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T14:47:35.266970Z","iopub.execute_input":"2022-11-17T14:47:35.267361Z","iopub.status.idle":"2022-11-17T14:47:35.282830Z","shell.execute_reply.started":"2022-11-17T14:47:35.267328Z","shell.execute_reply":"2022-11-17T14:47:35.281732Z"},"trusted":true},"execution_count":163,"outputs":[{"name":"stdout","text":"CustomNet(\n  (conv_layer1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n  (conv_layer2): Conv2d(32, 64, kernel_size=(4, 4), stride=(1, 1))\n  (conv_layer3): Conv2d(64, 128, kernel_size=(8, 8), stride=(1, 1))\n  (pooling_layer1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  (pooling_layer2): AvgPool2d(kernel_size=3, stride=3, padding=0)\n  (linear_layer1): Linear(in_features=128, out_features=64, bias=True)\n  (linear_layer2): Linear(in_features=64, out_features=32, bias=True)\n  (linear_layer3): Linear(in_features=32, out_features=1, bias=True)\n  (relu): ReLU()\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T14:40:53.335078Z","iopub.execute_input":"2022-11-17T14:40:53.335756Z","iopub.status.idle":"2022-11-17T14:40:53.341385Z","shell.execute_reply.started":"2022-11-17T14:40:53.335720Z","shell.execute_reply":"2022-11-17T14:40:53.340271Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"total_step = len(train_loader)\nmodel.train()\nfor epoch in range(5):\n    for i, (images, labels) in enumerate(train_loader): \n        images = images.to(device)\n        labels = labels.reshape(-1, 1).to(device)\n        \n        outputs = model(images)\n        loss = criterion(outputs, labels.float())\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 20 == 0:\n            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n                   .format(epoch+1, 5, i+1, total_step, loss.item()))","metadata":{"execution":{"iopub.status.busy":"2022-11-17T14:40:53.572651Z","iopub.execute_input":"2022-11-17T14:40:53.572938Z","iopub.status.idle":"2022-11-17T14:41:18.723893Z","shell.execute_reply.started":"2022-11-17T14:40:53.572912Z","shell.execute_reply":"2022-11-17T14:41:18.722205Z"},"trusted":true},"execution_count":161,"outputs":[{"name":"stdout","text":"Epoch [1/5], Step [20/60], Loss: 0.3718\nEpoch [1/5], Step [40/60], Loss: 0.2948\nEpoch [1/5], Step [60/60], Loss: 0.3631\nEpoch [2/5], Step [20/60], Loss: 0.2362\nEpoch [2/5], Step [40/60], Loss: 0.2094\nEpoch [2/5], Step [60/60], Loss: 0.2878\nEpoch [3/5], Step [20/60], Loss: 0.2462\nEpoch [3/5], Step [40/60], Loss: 0.3681\nEpoch [3/5], Step [60/60], Loss: 0.2548\nEpoch [4/5], Step [20/60], Loss: 0.3076\nEpoch [4/5], Step [40/60], Loss: 0.2443\nEpoch [4/5], Step [60/60], Loss: 0.2464\nEpoch [5/5], Step [20/60], Loss: 0.2155\nEpoch [5/5], Step [40/60], Loss: 0.2453\nEpoch [5/5], Step [60/60], Loss: 0.2163\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\nactivation = torch.nn.ReLU()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.reshape(-1, 1).to(device)\n        outputs = model(images)\n        predicted = (torch.sigmoid(outputs.data) > 0.5).float()\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print('Accuracy: {} %'.format(100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2022-11-17T14:41:18.725597Z","iopub.execute_input":"2022-11-17T14:41:18.725947Z","iopub.status.idle":"2022-11-17T14:41:21.331227Z","shell.execute_reply.started":"2022-11-17T14:41:18.725912Z","shell.execute_reply":"2022-11-17T14:41:21.330033Z"},"trusted":true},"execution_count":162,"outputs":[{"name":"stdout","text":"Accuracy: 91.12076994722136 %\n","output_type":"stream"}]}]}